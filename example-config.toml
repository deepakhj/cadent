[default]

## PID file to check if things is running already
pid_file="/tmp/consthash.pid"

## user this many proc while active (will default to the number on the machine)
# 0 == max CPUs
num_procs=0

## outgoing connections are pooled per outgoign server
## this sets the number of pool connections
## careful with this number, there will be this number * servers sending to connecitons
## (i.e. file descriptors limits may hit if this is too big)
max_pool_connections=10

## if you DO NOT want to pool connections (might be better for certain situations)
## `single` -> One connection = one line
## `pool` -> Pools connections to each server uses `max_pool_connections` for the pooling amount
sending_method="pool"


## Hashing Algo
# The hashing algo to use in our hashring
# 'crc32' -> default
# 'md5' -> the first 4 bytes of the MD5 (same one graphite uses)
# 'sha1' -> the first 4 bytes of the SHA1
# 'fnv' -> 32 bit FNV
# 'fnva' -> 32 bin FNVa -- a faster fnv
# 'nodejs-hashring' -> an "odd" bitshifting md5 one used by Statsd (nodejs-hashring really)
hasher_algo="md5"

## Hashing Etls
# The hashing elt that composes the acctual hashing server key
# 'graphite' -> the one graphite uses (default)
# 'statsd' -> the one statsd uses
# 'goconsistent' -> the one uses in the https://github.com/stathat/consistent
hasher_elter="graphite"

## Hasher vnodes
# the number of replicas per server
## graphite has 100 for this
## statsd has 40
## NOTE: this is NOT for "replication of data" but for how many virtual nodes are
## in the ConsistentHash ring per "real" node .. sometimes called "vnodes"
hasher_vnodes=40

## Data Replication
### for each line we get we can replicated it other nodes in the server
### list. (1 s the default, just send to one server)
num_dupe_replicas=1

## cache keys/server pairs in an LRU mem cache for speed
cache_items=50000

## Health Checking options
### check every "X" seconds
heartbeat_time_delay=60

### Timeout for failed connections (in Seconds)
heartbeat_time_timeout=1

## if a server has failed "X" times it's out of the loop
failed_heartbeat_count=3

## If we detect a downed node,
## `remove_node` -- we can REMOVE the node from the hashpool
## `ignore` -- stop checking the node
server_down_policy="remove_node"

## Turn on CPU/Mem profiling
##  there will be a http server set up to yank pprof data on :6060
cpu_profile=true

## fire out some internal to statsd if desired
statsd_server="192.168.59.103:8125"
statsd_prefix="consthash"
statsd_interval=1  # send to statd every second (buffered)

## number of workers to chew on the sending queue
## adjust this based on the input load
workers=200

## there will be an internal health http server set up as well
## and will respond to '/ops/status' -> "GET OK"
## '/stats' --> blob of json data (adding ?jsonp=xxx will return jsonp data)
## '/' --> a little file that charts (poorly) the above stats
internal_health_server_listen="0.0.0.0:6061"

## stats are "rendered" every 5 seconds, so this will keep last
## `internal_health_server_points` in RAM (careful with how many you store)
## (use the statsd emitter to store longer term stuff)
internal_health_server_points=500


## path to the html files for the internal health serer
internal_health_server_path="html"

### Server sections .. note all the above is overridable in each section
### (except the `statsd_*` and `internal_health_server_listen`)
### NOTE: `hasher_replicas` will NOT use the defaults, be explict there

[statsd-example]

## what port/scheme we are listening on for incoming data

listen="udp://127.0.0.1:8125"

## the list of servers we hashring send to
## {scheme}://{ip}:{port},...
## scheme = tcp|udp
servers="udp://192.168.59.103:8126,udp://192.168.59.103:8136, udp://192.168.59.103:8146"

## there must be a check server for each `servers` above
## {scheme}://{ip}:{port},...
## scheme = tcp|http -- NOTE NO UDP checks (does not make sense)
## tcp connections are simply checked for a connection and closed
## http connections must respond with a 200 to a GET on the provided url
check_servers="tcp://192.168.59.103:8127,tcp://192.168.59.103:8137, tcp://192.168.59.103:8147"

## msg_type = statsd | graphite | regex
## <key>:<stat>
msg_type="statsd"

# statsd style
hasher_algo="nodejs-hashring"
hasher_elter="statsd"
hasher_vnodes=40

[graphite-example]

## msg_type = statsd | graphite | regex
## <time> <key> <value>
msg_type="graphite"

# graphite style
hasher_algo="md5"
hasher_elter="graphite"
hasher_vnodes=100

servers="tcp://127.0.0.1:2003,tcp://127.0.0.1:2013,tcp://127.0.0.1:2023"
#checks will default to the servers

[regex-example]

# syslog like to farm specific hosts
listen="udp://127.0.0.1:6004"

servers="udp://127.0.0.1:6080,udp://127.0.0.1:6081,udp://127.0.0.1:6082"
check_servers="tcp://127.0.0.1:6090,tcp://127.0.0.1:6091,tcp://127.0.0.1:6092"

## msg_type = statsd | graphite | regex
## NOTE  msg_regex needs to have (?P<Key>..) named bit
msg_type="regex"
## NOTE: SINGLE QUOTES ARE IMPORTANT otherwise it will try to unescape the string
msg_regex='^(<\d+>)?(?P<Timestamp>[A-Z][a-z]+\s+\d+\s\d+:\d+:\d+) (?P<Key>\S+) (?P<Logger>\S+):(.*)'
hasher_algo="fnv"



